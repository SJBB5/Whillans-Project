{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b828c4f-5e64-41ce-a295-5b554bcf099a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sam Brown\n",
    "# sam_brown@mines.edu\n",
    "# July 14\n",
    "# Goal: Investigate different ways to calculate the energy of a slip event and look for trends mg stations\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Stations import Station\n",
    "import my_lib.funcs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from netCDF4 import Dataset\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2e1e388-8a49-4454-b451-c4080f862e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in antarctica ice depth data\n",
    "filepath = \"/Users/sambrown04/Documents/SURF/NSIDC-0756_3-20250708_204745/BedMachineAntarctica-v3.nc\"\n",
    "ds = xr.open_dataset(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abf3defa-4828-4405-972f-a547071f64ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mg01x = -178462.5466582153 \n",
    "mg01y = -555835.6719349005\n",
    "\n",
    "mg06x = -189291.11945724243 \n",
    "mg06y = -570212.4036758058\n",
    "\n",
    "mg07x = -185263.18872241525 \n",
    "mg07y = -558217.6317621776\n",
    "\n",
    "mg04x = -181853.9877418033 \n",
    "mg04y = -560788.2678059591\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e42480a7-6878-4251-b676-4e23d656d913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mg01: 872.15 meters\n",
      "mg04: 831.70 meters\n",
      "mg06: 758.22 meters\n",
      "mg07: 855.19 meters\n"
     ]
    }
   ],
   "source": [
    "coords = {\n",
    "    'mg01': (-178462.5466582153, -555835.6719349005),\n",
    "    'mg04': (-181853.9877418033,  -560788.2678059591),\n",
    "    'mg06': (-189291.11945724243, -570212.4036758058),\n",
    "    'mg07': (-185263.18872241525, -558217.6317621776)\n",
    "}\n",
    "\n",
    "for label, (x_val, y_val) in coords.items():\n",
    "    thickness = ds['thickness'].sel(x=x_val, y=y_val, method='nearest')\n",
    "    print(f\"{label}: {thickness.values:.2f} meters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b8ed0e-949c-43f4-9b7f-157aade3f28e",
   "metadata": {},
   "source": [
    "Shoelace formula:\n",
    "$$\n",
    "A = \\frac{1}{2} \\left| \\sum_{i=1}^{n} (x_i y_{i+1} - x_{i+1} y_i) \\right|\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "881ece2d-9665-461f-ae51-287437812c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area: 23187612.92 square meters\n"
     ]
    }
   ],
   "source": [
    "avg = 829.32\n",
    "\n",
    "# Use a triangle to calculate the area and the volume using shoelace formula\n",
    "x = np.array([\n",
    "    -178462.5466582153,  # mg01\n",
    "    -189291.11945724243, # mg06\n",
    "    -185263.18872241525, # mg07\n",
    "    -181853.9877418033   # mg04\n",
    "])\n",
    "\n",
    "y = np.array([\n",
    "    -555835.6719349005,  # mg01\n",
    "    -570212.4036758058,  # mg06\n",
    "    -558217.6317621776,  # mg07\n",
    "    -560788.2678059591   # mg04\n",
    "])\n",
    "\n",
    "# append the first point to the end\n",
    "x_closed = np.append(x, x[0])\n",
    "y_closed = np.append(y, y[0])\n",
    "\n",
    "\n",
    "sum1 = np.sum(x_closed[:-1] * y_closed[1:])\n",
    "sum2 = np.sum(y_closed[:-1] * x_closed[1:])\n",
    "area_m2 = 0.5 * np.abs(sum1 - sum2)\n",
    "\n",
    "\n",
    "print(f\"Area: {area_m2:.2f} square meters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "34208644-eec3-47df-8e8d-40337cb602a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = area_m2 * avg\n",
    "density = 910 # kg/m^3\n",
    "mass = vol * density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ea0987ad-3aa4-49cc-9980-3b121bfe90a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use 2014 data because that is the only time these stations were up consistently \n",
    "df14 = my_lib.funcs.load_evt(\"/Users/sambrown04/Documents/SURF/Events/2014_2014Events2stas\")\n",
    "df14 = my_lib.funcs.preprocess_events(df14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8075b9a4-5f49-4352-9f50-3afb84c1d6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter so it is only mg stations\n",
    "mg_dat = []\n",
    "\n",
    "for i, event in enumerate(df14):\n",
    "\n",
    "    filt_df = pd.DataFrame()\n",
    "    \n",
    "    for col in event.columns:\n",
    "        colname = col[0:2]\n",
    "        if colname == 'mg' or colname == 'ti' or colname == 'ti':\n",
    "            column = event[col].copy()\n",
    "            filt_df[col] = column\n",
    "            \n",
    "    mg_dat.append(filt_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8c377448-bcef-4a12-bdfd-e215a10925d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping event 26: no valid onsets found.\n",
      "Skipping event 28: no valid onsets found.\n",
      "Skipping short event 33: only 2 samples.\n",
      "Skipping event 37: no valid onsets found.\n",
      "Skipping event 42: no valid onsets found.\n",
      "Skipping event 48: no valid onsets found.\n",
      "Skipping event 59: no valid onsets found.\n",
      "Skipping event 61: no valid onsets found.\n",
      "Skipping event 82: no valid onsets found.\n",
      "Skipping short event 91: only 8 samples.\n",
      "Skipping event 98: no valid onsets found.\n",
      "Skipping event 119: no valid onsets found.\n",
      "Skipping event 131: no valid onsets found.\n",
      "Skipping event 133: no valid onsets found.\n",
      "Skipping event 135: no valid onsets found.\n",
      "Skipping event 140: no valid onsets found.\n",
      "Skipping event 155: no valid onsets found.\n",
      "Skipping short event 170: only 1 samples.\n",
      "Skipping event 180: no valid onsets found.\n",
      "Skipping short event 189: only 3 samples.\n",
      "Skipping event 210: no valid onsets found.\n",
      "Skipping short event 215: only 8 samples.\n",
      "Skipping short event 219: only 16 samples.\n",
      "Skipping event 224: no valid onsets found.\n",
      "Skipping event 234: no valid onsets found.\n",
      "Skipping event 236: no valid onsets found.\n",
      "Skipping event 237: no valid onsets found.\n",
      "Skipping event 253: no valid onsets found.\n",
      "Skipping event 272: no valid onsets found.\n",
      "Skipping event 280: no valid onsets found.\n",
      "Skipping short event 293: only 1 samples.\n",
      "Skipping event 297: no valid onsets found.\n",
      "Skipping short event 302: only 1 samples.\n",
      "Skipping event 303: no valid onsets found.\n",
      "Skipping event 305: no valid onsets found.\n",
      "Skipping event 308: no valid onsets found.\n",
      "Skipping event 311: no valid onsets found.\n",
      "Skipping event 318: no valid onsets found.\n",
      "Skipping event 334: no valid onsets found.\n",
      "Skipping event 347: no valid onsets found.\n",
      "Skipping event 357: no valid onsets found.\n",
      "Skipping event 369: no valid onsets found.\n",
      "Skipping event 373: no valid onsets found.\n",
      "Skipping event 390: no valid onsets found.\n",
      "Skipping event 391: no valid onsets found.\n",
      "Skipping event 440: no valid onsets found.\n",
      "Skipping event 442: no valid onsets found.\n",
      "Skipping event 448: no valid onsets found.\n",
      "Skipping event 455: no valid onsets found.\n",
      "Skipping event 456: no valid onsets found.\n",
      "Skipping short event 460: only 2 samples.\n",
      "Skipping event 464: no valid onsets found.\n",
      "Skipping event 465: no valid onsets found.\n",
      "Skipping event 483: no valid onsets found.\n",
      "Skipping event 486: no valid onsets found.\n"
     ]
    }
   ],
   "source": [
    "f_events = []\n",
    "derivs_events = []\n",
    "energies = pd.DataFrame(columns=['date', 'evt_energy'])\n",
    "\n",
    "dt = 15  # Time step in seconds\n",
    "mass = mass  # Assumed to be defined earlier\n",
    "\n",
    "for i, event in enumerate(mg_dat):\n",
    "    cols = [col for col in event.columns if col not in ['time_sec', 'time_dt']]\n",
    "    event_onsets = []\n",
    "\n",
    "    for col in cols:\n",
    "        # Compute first and second derivatives\n",
    "        grad = my_lib.funcs.derivative(event[col].values)\n",
    "        grad2 = my_lib.funcs.derivative(grad)\n",
    "\n",
    "        # Identify max of second derivative (absolute value)\n",
    "        max_idx = np.argmax(np.abs(grad2))\n",
    "        max_time = event['time_sec'].iloc[max_idx]\n",
    "        event_onsets.append(max_time)\n",
    "\n",
    "    # Skip if no valid onset found\n",
    "    if not event_onsets:\n",
    "        print(f\"Skipping event {i}: no valid onsets found.\")\n",
    "        continue\n",
    "\n",
    "    # Store date from original (unspliced) event\n",
    "    date = event['time_dt'].iloc[0]\n",
    "\n",
    "    # Determine the release time as the max of onsets\n",
    "    release_time = max(event_onsets)\n",
    "\n",
    "    # Splice the event starting from release_time\n",
    "    spliced_event = event[event['time_sec'] >= release_time].reset_index(drop=True)\n",
    "\n",
    "    # Skip if spliced event too short\n",
    "    if spliced_event.shape[0] < 50:\n",
    "        print(f\"Skipping short event {i}: only {spliced_event.shape[0]} samples.\")\n",
    "        continue\n",
    "\n",
    "    # Compute average displacement\n",
    "    cols_avg = [col for col in spliced_event.columns if col not in ['time_sec', 'time_dt']]\n",
    "    spliced_event['avg_disp'] = spliced_event[cols_avg].mean(axis=1)\n",
    "\n",
    "    # Compute derivative of average displacement\n",
    "    deriv = my_lib.funcs.derivative(spliced_event['avg_disp'])\n",
    "\n",
    "    f_events.append(spliced_event)\n",
    "\n",
    "    # Store (date, derivative) pair\n",
    "    derivs_events.append((date, deriv))\n",
    "\n",
    "    # Compute and store energy\n",
    "    evt_E = event_energy(deriv, mass, dt)\n",
    "    energies.loc[len(energies)] = {\n",
    "        \"date\": date,\n",
    "        \"evt_energy\": evt_E\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dd6125e3-1d39-4c1e-8349-347dcb154f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def event_energy(velocity_arr, mass, dt=15):\n",
    "    kinetic_energy = 0.5 * mass * velocity_arr**2  # Joules at each step\n",
    "    total_energy = np.sum(kinetic_energy) * dt       # Approximate integration\n",
    "    return total_energy  # in joules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a508c68e-00d1-4485-894c-aab9c8b8b51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(466, 2)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9e9ba400-419e-4e76-b6ea-957f5d07ef73",
   "metadata": {},
   "outputs": [],
   "source": [
    "energies.to_csv('Energies_mg', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
